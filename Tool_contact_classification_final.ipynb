{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tool_contact_classification_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAniRMluapBB+wbSzBdO5m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joiljoe89/deep-learning-in-computer-vision/blob/master/Tool_contact_classification_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connnect to google drive"
      ],
      "metadata": {
        "id": "f5HHmlamOBTL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex6v0uBPZ_RG",
        "outputId": "6c6a530d-b11c-4c35-a133-a38b92837f5b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTS\n",
        "We will use Keras (Tensorflow 2) for building our ResNet model and h5py to load data"
      ],
      "metadata": {
        "id": "Qb4ePn4WOKaX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCLHKLdVN4aJ"
      },
      "source": [
        "import os\n",
        "#import h5py\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "%matplotlib inline\n",
        "import tensorflow.keras.backend as K\n",
        "# Image dataset has channels as its last dimensions\n",
        "K.set_image_data_format('channels_last')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD DATA\n",
        "Tool calibration Dataset"
      ],
      "metadata": {
        "id": "et4cVAGsOPG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For the given path, get the List of all files in the directory tree \n",
        "def getListOfFiles(dirName):\n",
        "    # create a list of file and sub directories \n",
        "    # names in the given directory \n",
        "    listOfFile = os.listdir(dirName)\n",
        "    allFiles = list()\n",
        "    # Iterate over all the entries\n",
        "    for entry in listOfFile:\n",
        "        # Create full path\n",
        "        fullPath = os.path.join(dirName, entry)\n",
        "        # If entry is a directory then get the list of files in this directory \n",
        "        if os.path.isdir(fullPath):\n",
        "            allFiles = allFiles + getListOfFiles(fullPath)\n",
        "        else:\n",
        "            allFiles.append(fullPath)\n",
        "                \n",
        "    return allFiles"
      ],
      "metadata": {
        "id": "A529CkuEdsH2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "\n",
        "img_c1 = cv2.imread('/content/drive/My Drive/Contact_check/train/noContact/frame0.jpg')\n",
        "img_c1 = cv2.resize(img_c1, (224,224), interpolation = cv2.INTER_CUBIC)\n",
        "img_c1 = np.array(img_c1)\n",
        "\n",
        "#img_c3 = cv2.imread('/home/joe/Desktop/sgan/train/patch/train_data/grass/ocn10.jpg')\n",
        "\n",
        "input_img = 0\n",
        "\n",
        "# training images\n",
        "\n",
        "dirName_c1 = '/content/drive/My Drive/Contact_check/train/noContact';\n",
        "dirName_c2 = '/content/drive/My Drive/Contact_check/train/Contact';\n",
        "#dirName_c3 = '/home/joe/Desktop/sgan/train/patch/train_data/grass';\n",
        "\n",
        "# Get the list of all files in directory tree at given path\n",
        "listOfFiles_c1 = getListOfFiles(dirName_c1)\n",
        "listOfFiles_c1 = sorted(listOfFiles_c1)\n",
        "listOfFiles_c2 = getListOfFiles(dirName_c2)\n",
        "listOfFiles_c2 = sorted(listOfFiles_c2)\n",
        "#listOfFiles_c3 = getListOfFiles(dirName_c3)\n",
        "#listOfFiles_c3 = sorted(listOfFiles_c3)\n",
        "\n",
        "print('total training nonContact images:', len(os.listdir(dirName_c1)))\n",
        "num_img_c1 = len(os.listdir(dirName_c1))\n",
        "print('total training Contact images:', len(os.listdir(dirName_c2)))\n",
        "num_img_c2 = len(os.listdir(dirName_c2))\n",
        "\n",
        "# Print the files\n",
        "for elem_c1 in listOfFiles_c1:\n",
        "  #print(elem_c1[54::])\n",
        "  img_in = cv2.imread('/content/drive/My Drive/Contact_check/train/noContact/'+elem_c1[54::])\n",
        "  img_in = cv2.resize(img_in, (224,224), interpolation = cv2.INTER_CUBIC) #INTER_NEAREST,INTER_LINEAR,INTER_CUBIC,INTER_LANCZOS4 \n",
        "  img_in =np.array(img_in)\n",
        "  #print(img_c1.shape)\n",
        "  input_img = np.append(img_in,img_c1, axis=0)\n",
        "  img_c1 = input_img\n",
        "print(img_c1.shape)\n",
        "\n",
        "for elem_c2 in listOfFiles_c2:\n",
        "  #print(elem_c2[52::])\n",
        "  img_in = cv2.imread('/content/drive/My Drive/Contact_check/train/Contact/'+elem_c2[52::])\n",
        "  img_in = cv2.resize(img_in, (224,224), interpolation = cv2.INTER_CUBIC)\n",
        "  img_in =np.array(img_in)\n",
        "  input_img = np.append(img_c1,img_in, axis=0)\n",
        "  img_c1 = input_img\n",
        "print(img_c1.shape)\n",
        "img_c1 = img_c1.reshape(1+num_img_c1+num_img_c2,224,224,3)\n",
        "\n",
        "input_img = 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBLNf_GZe9Cz",
        "outputId": "51f91074-88f4-450d-8811-58a2ae9b6532"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training nonContact images: 415\n",
            "total training Contact images: 34\n",
            "(93184, 224, 3)\n",
            "(100800, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_img = 0\n",
        "#print(img_c1.shape,img_c2.shape,img_c3.shape,img_c4.shape,img_c5.shape)\n",
        "#nb_img_c1 = int(img_c1.shape[0]/200)\n",
        "\n",
        "max_value = 255.0\n",
        "X_train = img_c1.astype('float32') / max_value\n",
        "#img_c2 =img_c2.astype('float32') / max_value\n",
        "\n",
        "#X_train = X_train.reshape(img_c1[0] + img_c2[0],224,224,3)\n",
        "print('total data:', X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlWy-Gxrg3in",
        "outputId": "76775990-68dd-46ac-a8d5-b71446c94dc0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total data: (450, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.append(np.zeros((num_img_c1+1,2)),np.ones((num_img_c2,2)), axis=0)\n",
        "#y_train = np.append(y_train,2*np.ones(nb_img_c3))\n",
        "Y_train = y_train#.reshape(X_train[0], 2)\n",
        "print('total label',Y_train.shape)\n",
        "\n",
        "\n",
        "print (\"********************train data complete****************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HkxTLH5Rf4p",
        "outputId": "f429b06c-dacc-442a-9259-f8cd07fefd93"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total label (450, 2)\n",
            "********************train data complete****************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IDENTITY BLOCK\n",
        "\n",
        "A block of layers with skip connection, where the input activation (say a[i]) has the same dimension as the output activation (say a[i+n] where n is number of layers in the block) is an identity block in a ResNet. The skip-connection or shortcut is reffered to the path 1 in the figure. While path 2 is the main path.\n",
        "\n",
        "Structure of our identity block"
      ],
      "metadata": {
        "id": "olYnnPsmPNQ6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbYJUA-Sgs-f"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "\n",
        "  '''\n",
        "  Implementation of identity block described above\n",
        "\n",
        "  Arguments:\n",
        "  X -       input tensor to the block of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "  f -       defines shpae of filter in the middle layer of the main path\n",
        "  filters - list of integers, defining the number of filters in each layer of the main path\n",
        "  stage -   defines the block position in the network\n",
        "  block -   used for naming convention\n",
        "\n",
        "  Returns: \n",
        "  X - output is a tensor of shape (n_H, n_W, n_C) which matches (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "  '''\n",
        "\n",
        "  # defining base name for block\n",
        "  conv_base_name = 'res' + str(stage) + block + '_'\n",
        "  bn_base_name = 'bn' + str(stage) + block + '_'\n",
        "\n",
        "  # retrieve number of filters in each layer of main path\n",
        "  # NOTE: f3 must be equal to n_C. That way dimensions of the third component will match the dimension of original input to identity block\n",
        "  f1, f2, f3 = filters\n",
        "\n",
        "  # Batch normalization must be performed on the 'channels' axis for input. It is 3, for our case\n",
        "  bn_axis = 3\n",
        "\n",
        "  # save input for \"addition\" to last layer output; step in skip-connection\n",
        "  X_skip_connection = X\n",
        "\n",
        "  # ----------------------------------------------------------------------\n",
        "  # Building layers/component of identity block using Keras functional API\n",
        "\n",
        "  # First component/layer of main path\n",
        "  X = Conv2D(filters= f1, kernel_size = (1,1), strides = (1,1), padding='valid', name=conv_base_name+'first_component', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = BatchNormalization(axis=bn_axis, name=bn_base_name+'first_component')(X)\n",
        "  X = Activation('relu')(X)\n",
        "  \n",
        "  # Second component/layer of main path\n",
        "  X = Conv2D(filters= f2, kernel_size = (f,f), strides = (1,1), padding='same', name=conv_base_name+'second_component', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = BatchNormalization(axis=bn_axis, name=bn_base_name+'second_component')(X)\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  # Third component/layer of main path\n",
        "  X = Conv2D(filters= f3, kernel_size = (1,1), strides = (1,1), padding='valid', name=conv_base_name+'third_component', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "  X = BatchNormalization(axis=bn_axis, name=bn_base_name+'third_component')(X)\n",
        "  \n",
        "  # \"Addition step\" - skip-connection value merges with main path\n",
        "  # NOTE: both values have same dimensions at this point, so no operation is required to match dimensions\n",
        "  X = Add()([X, X_skip_connection])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  return X"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONVOLUTIONAL BLOCK\n",
        "\n",
        "This is another kind of block with skip-connection in the ResNet. In this the input to block, and output of last layer in the block don't match in dimensions. So we need to add a convolution step in the skip-connection, before adding the input to last layer's output. This convolution step changes the dimension of the input, so that the dimensions match up for the later addition step."
      ],
      "metadata": {
        "id": "SMfvEOE2PkwQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOyhiSzxrj--"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in above figure\n",
        "    \n",
        "    Arguments:\n",
        "    X -       input tensor to the block of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -       defines shape of filter in the middle layer of the main path\n",
        "    filters - list of integers, defining the number of filters in each layer of the main path\n",
        "    stage -   defines the block position in the network\n",
        "    block -   used for naming convention\n",
        "    s -       specifies the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining base name for block\n",
        "    conv_base_name = 'res' + str(stage) + block + '_'\n",
        "    bn_base_name = 'bn' + str(stage) + block + '_'\n",
        "    \n",
        "    # retrieve number of filters in each layer of main path\n",
        "    f1, f2, f3 = filters\n",
        "    \n",
        "    # Batch normalization must be performed on the 'channels' axis for input. It is 3, for our case\n",
        "    bn_axis = 3\n",
        "\n",
        "    # save input for \"addition\" to last layer output; step in skip-connection\n",
        "    X_skip_connection = X\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(f1, (1, 1), strides = (s,s), padding = 'valid', name = conv_base_name + 'first_component', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = bn_axis, name = bn_base_name + 'first_component')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path\n",
        "    X = Conv2D(f2,  kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_base_name + 'second_component', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = bn_axis, name = bn_base_name + 'second_component')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(f3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_base_name + 'third_component', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = bn_axis, name = bn_base_name + 'third_component')(X)\n",
        "\n",
        "    ##### Convolve skip-connection value to match its dimensions to third layer output's dimensions #### \n",
        "    X_skip_connection = Conv2D(f3, (1, 1), strides = (s,s), padding = 'valid', name = conv_base_name + 'merge', kernel_initializer = glorot_uniform(seed=0))(X_skip_connection)\n",
        "    X_skip_connection = BatchNormalization(axis = 3, name = bn_base_name + 'merge')(X_skip_connection)\n",
        "\n",
        "    # \"Addition step\" \n",
        "    # NOTE: both values have same dimensions at this point\n",
        "    X = Add()([X, X_skip_connection])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESNET50\n",
        "\n",
        "Now that we have our building blocks - Convolutional block and identity block in place, we will build a 50 layer deep neural network with skip connections that implements the follwoing architecture"
      ],
      "metadata": {
        "id": "myFBMWeDPsg-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAA3cR4A-kG0"
      },
      "source": [
        "def ResNet50(input_shape = (64, 64, 3), classes = 2):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    input_shape - shape of the images of the dataset\n",
        "    classes - number of classes\n",
        "\n",
        "    Returns:\n",
        "    model - a Model() instance in Keras\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # plug in input_shape to define the input tensor\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding : pads the input with a pad of (3,3)\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv_1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # NOTE: dimensions of filters that are passed to identity block are such that final layer output\n",
        "    # in identity block mathces the original input to the block\n",
        "    # blocks in each stage are alphabetically sequenced\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # Average Pooling\n",
        "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tcSKMMyDilb"
      },
      "source": [
        "model = ResNet50(input_shape = (224, 224, 3), classes = 2)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Kuo8yDNHQfrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN RESNET50"
      ],
      "metadata": {
        "id": "-RqaQhlpP32P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWUBnt4dfg3K",
        "outputId": "91107228-2952-4028-e829-cc683227973f"
      },
      "source": [
        "model.fit(X_train, Y_train, epochs = 2, batch_size = 16)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "29/29 [==============================] - 284s 10s/step - loss: 0.1315 - accuracy: 0.4444\n",
            "Epoch 2/2\n",
            "29/29 [==============================] - 278s 10s/step - loss: 0.1208 - accuracy: 0.4711\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdb12456550>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyVDMaTQmDnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d644d5-a5ad-44f1-fb88-40a7c9a846f2"
      },
      "source": [
        "model.save('/content/drive/MyDrive/ResNet50/model/RESNET50.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST PERFORMANCE"
      ],
      "metadata": {
        "id": "7Cm-kpZ5QBNH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BEboK3RgVwc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cecf55f-e52c-4914-cf17-ba67cab1865a"
      },
      "source": [
        "predictions = model.evaluate(X_train, Y_train)\n",
        "print(\"Loss = \" + str(predictions[0]))\n",
        "print(\"Test Accuracy = \" + str(predictions[1]))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 61s 4s/step - loss: 0.5092 - accuracy: 0.8911\n",
            "Loss = 0.5091859698295593\n",
            "Test Accuracy = 0.8911111354827881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUHgzt0Bny1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e869e380-f845-452c-a2a9-5afca528b296"
      },
      "source": [
        "new_model = load_model('/content/drive/MyDrive/ResNet50/model/RESNET50.h5')\n",
        "predictions = new_model.evaluate(X_test, Y_test)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 3s 521ms/step - loss: 0.2398 - accuracy: 0.9500\n",
            "[0.239801824092865, 0.949999988079071]\n"
          ]
        }
      ]
    }
  ]
}